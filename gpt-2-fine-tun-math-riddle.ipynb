{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:12.936433Z",
     "iopub.status.busy": "2025-03-10T06:46:12.936107Z",
     "iopub.status.idle": "2025-03-10T06:46:16.446892Z",
     "shell.execute_reply": "2025-03-10T06:46:16.445737Z",
     "shell.execute_reply.started": "2025-03-10T06:46:12.936407Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from trl) (1.2.1)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from trl) (3.3.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.47.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (2.5.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.29.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.0->trl) (0.4.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.21.0->trl) (3.11.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.0->trl) (0.21.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (2.19.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2025.1.31)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.21.0->trl) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<3.0.0,>=1.17->accelerate>=0.34.0->trl) (2024.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:16.449271Z",
     "iopub.status.busy": "2025-03-10T06:46:16.448927Z",
     "iopub.status.idle": "2025-03-10T06:46:19.257533Z",
     "shell.execute_reply": "2025-03-10T06:46:19.256694Z",
     "shell.execute_reply.started": "2025-03-10T06:46:16.449246Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import DatasetDict, Dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:19.259470Z",
     "iopub.status.busy": "2025-03-10T06:46:19.259157Z",
     "iopub.status.idle": "2025-03-10T06:46:19.320397Z",
     "shell.execute_reply": "2025-03-10T06:46:19.319411Z",
     "shell.execute_reply.started": "2025-03-10T06:46:19.259439Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n"
     ]
    }
   ],
   "source": [
    "# Check and Set CUDA\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:19.322101Z",
     "iopub.status.busy": "2025-03-10T06:46:19.321767Z",
     "iopub.status.idle": "2025-03-10T06:46:19.376605Z",
     "shell.execute_reply": "2025-03-10T06:46:19.375830Z",
     "shell.execute_reply.started": "2025-03-10T06:46:19.322068Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(\"/kaggle/input/dataset1/math_riddles.csv\")\n",
    "\n",
    "# Split Dataset (80% train, 10% validation, 10% test)\n",
    "def split_dataset(df):\n",
    "    train_size = int(0.8 * len(df))  # 5 samples\n",
    "    val_size = int(0.1 * len(df))    # 1 sample\n",
    "    test_size = len(df) - train_size - val_size  # 1 sample\n",
    "    \n",
    "    train_df = df[:train_size]\n",
    "    val_df = df[train_size:train_size + val_size]\n",
    "    test_df = df[train_size + val_size:]\n",
    "    \n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "train_df, val_df, test_df = split_dataset(df)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_df),\n",
    "    \"validation\": Dataset.from_pandas(val_df),\n",
    "    \"test\": Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:19.377625Z",
     "iopub.status.busy": "2025-03-10T06:46:19.377325Z",
     "iopub.status.idle": "2025-03-10T06:46:24.360594Z",
     "shell.execute_reply": "2025-03-10T06:46:24.359662Z",
     "shell.execute_reply.started": "2025-03-10T06:46:19.377590Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be61042c5204469b9ad3858368a632cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a493be8d574dddbefb43bb31141a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93cf4674ea294a9cb3915743d3104434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62df56b558bc4d86923c33677e685845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d9e8016a634e599ba3cab9926f3c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9019b833fb2a49f6ba029143bca84e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "172c4f295cb94d8f8fc482c644d4a1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4f55d8e54b4e9792bef03f41124dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7d5958460f42eca4a7bf28c3b69f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850f41ebc1ef4dbd8eb408ee7c7dec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Tokenizer and Model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\", torch_dtype=torch.float16, device_map=\"auto\")\n",
    "\n",
    "# Preprocessing: Format as full prompts\n",
    "def preprocess_function(examples):\n",
    "    prompts = [f\"Math Riddle: {riddle}\\nAnswer: {answer}\" for riddle, answer in zip(examples[\"riddle\"], examples[\"answer\"])]\n",
    "    return tokenizer(prompts, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:24.361872Z",
     "iopub.status.busy": "2025-03-10T06:46:24.361562Z",
     "iopub.status.idle": "2025-03-10T06:46:24.448915Z",
     "shell.execute_reply": "2025-03-10T06:46:24.448021Z",
     "shell.execute_reply.started": "2025-03-10T06:46:24.361847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,008 || all params: 125,250,816 || trainable%: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora/layer.py:1264: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LoRA Configuration\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"c_attn\", \"c_proj\"]  # Focus on attention layers for GPT-2\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:24.449966Z",
     "iopub.status.busy": "2025-03-10T06:46:24.449649Z",
     "iopub.status.idle": "2025-03-10T06:46:34.139690Z",
     "shell.execute_reply": "2025-03-10T06:46:34.138932Z",
     "shell.execute_reply.started": "2025-03-10T06:46:24.449943Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff7af4f3cc04f31bbf9d045ce6e6581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting train dataset to ChatML:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08adbeb353f54cd480bec8b7adb8b922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d569b4b749cc49aaa99e9ce174afdd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/24 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d707063622064c15a59ffd6d09543ca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Converting eval dataset to ChatML:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3e75a8af0e47388aedc474fd46e6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to eval dataset:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27aec69a30e841358c252f4aeac7ad54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating eval dataset:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [96/96 00:07, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.403400</td>\n",
       "      <td>3.982834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.456900</td>\n",
       "      <td>3.887849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.354600</td>\n",
       "      <td>3.765164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.242400</td>\n",
       "      <td>3.643247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.620000</td>\n",
       "      <td>3.527553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.436000</td>\n",
       "      <td>3.435995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.426100</td>\n",
       "      <td>3.377908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.382300</td>\n",
       "      <td>3.360038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/kaggle/working/riddle_model\",\n",
    "    per_device_train_batch_size=2,\n",
    "    num_train_epochs=8,  # Matches assignment requirement\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"/kaggle/working/logs\",\n",
    "    report_to=\"none\",\n",
    "    eval_strategy=\"epoch\",  # Updated from evaluation_strategy\n",
    "    fp16=True,\n",
    "    logging_steps=1  # Log frequently due to small dataset\n",
    ")\n",
    "\n",
    "# Trainer Setup\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    processing_class=tokenizer,  # Updated from tokenizer\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.train()\n",
    "trainer.train()\n",
    "\n",
    "# Save Model\n",
    "trainer.model.save_pretrained(\"/kaggle/working/trained-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:34.141694Z",
     "iopub.status.busy": "2025-03-10T06:46:34.141487Z",
     "iopub.status.idle": "2025-03-10T06:46:38.483547Z",
     "shell.execute_reply": "2025-03-10T06:46:38.482809Z",
     "shell.execute_reply.started": "2025-03-10T06:46:34.141675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Riddles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Riddle 1: Math Riddle:  How do you find out if you've been on a train for 5 minutes or less?  How do you determine if you're going to be able to take a break?  How do you find out if you're going to be able to\n",
      "Riddle 2: Math Riddle:  Is there any way to answer the question of how many times we have done this before?  Is there any way to answer the question of how many times we have done this before?  Or is there a way to answer the question\n",
      "Riddle 3: Math Riddle:  The following is a description of a simple riddle (a \"bunny\" in the words) that I have found to be very difficult to solve. I have been trying to solve this riddle for the past year.\n",
      "The answer is\n",
      "Riddle 4: Math Riddle:  (1)  What is the probability of a dog being killed by a human?  (2)  What is the probability of a dog being killed by a human?  (3)  What is the probability\n",
      "Riddle 5: Math Riddle:  Can we have an answer to the puzzle of how to make a bullet out of a bullet?  Answer:  I don't know.  I have been working on this for a couple of weeks.  I've got\n"
     ]
    }
   ],
   "source": [
    "# Generate 5 Riddles\n",
    "def generate_riddle(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        do_sample=True  # Enable sampling for creativity\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"\\nGenerated Riddles:\")\n",
    "generated_riddles = [generate_riddle(\"Math Riddle: \") for _ in range(5)]\n",
    "for i, riddle in enumerate(generated_riddles):\n",
    "    print(f\"Riddle {i+1}: {riddle}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-10T06:46:38.484598Z",
     "iopub.status.busy": "2025-03-10T06:46:38.484397Z",
     "iopub.status.idle": "2025-03-10T06:46:38.490654Z",
     "shell.execute_reply": "2025-03-10T06:46:38.489985Z",
     "shell.execute_reply.started": "2025-03-10T06:46:38.484580Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Manual Evaluation:\n",
      "Invalid format: Math Riddle:  How do you find out if you've been on a train for 5 minutes or less?  How do you determine if you're going to be able to take a break?  How do you find out if you're going to be able to\n",
      "Invalid format: Math Riddle:  Is there any way to answer the question of how many times we have done this before?  Is there any way to answer the question of how many times we have done this before?  Or is there a way to answer the question\n",
      "Invalid format: Math Riddle:  The following is a description of a simple riddle (a \"bunny\" in the words) that I have found to be very difficult to solve. I have been trying to solve this riddle for the past year.\n",
      "The answer is\n",
      "Invalid format: Math Riddle:  (1)  What is the probability of a dog being killed by a human?  (2)  What is the probability of a dog being killed by a human?  (3)  What is the probability\n",
      "Riddle: Math Riddle:  Can we have an answer to the puzzle of how to make a bullet out of a bullet?\n",
      "Stated Answer: I don't know.  I have been working on this for a couple of weeks.  I've got\n"
     ]
    }
   ],
   "source": [
    "# Basic Evaluation (Manual Check)\n",
    "print(\"\\nManual Evaluation:\")\n",
    "for riddle in generated_riddles:\n",
    "    try:\n",
    "        riddle_text = riddle.split(\"Answer:\")[0].strip()\n",
    "        answer = riddle.split(\"Answer:\")[1].strip()\n",
    "        print(f\"Riddle: {riddle_text}\")\n",
    "        print(f\"Stated Answer: {answer}\")\n",
    "        # Add manual verification logic here if needed\n",
    "    except IndexError:\n",
    "        print(f\"Invalid format: {riddle}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6822054,
     "sourceId": 10964947,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
